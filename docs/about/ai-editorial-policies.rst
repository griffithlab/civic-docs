AI Editorial Policies
=====================

.. contents::
   :backlinks: entry

CIViC (Clinical Interpretation of Variants in Cancer) is an open-access, community-driven knowledgebase designed to capture and disseminate expert knowledge about the clinical significance of cancer genetic variants. From its inception, CIViC has fundamentally been a human created and curated resource, and maintaining this foundation of CIViC as a human curated dataset will remain a priority moving forward. As an evolving resource at the intersection of genomics and precision medicine, CIViC also embraces innovation that can enhance curation efficiency and quality. AI and large language models (LLMs) are powerful tools that can assist curation, validation, and editorial workflows. To ensure that CIViC remains a trustworthy, accurate, human curated, and useful resource to scientific and medical communities, we have established these policies to govern the fundamental creative knowledge work that CIViC facilitates. These policies outline how AI tools may or may not be used, balancing the benefits of AI assistance with the need for human accountability and oversight.

Our goals with these AI policies are to:

* **Maintain the integrity and reliability of CIViC’s content,** so that every record is backed by evidence and expert judgement.
* **Encourage responsible use of AI** to aid contributors in literature review, curation, and verification, while preventing misuse of AI that could introduce errors, hallucinations, or bias.
* **Protect the collaborative and educational spirit of CIViC,** ensuring that AI assistance augments human expertise rather than replacing it.
* **Provide clarity** on what kinds of AI-assisted work are allowed or prohibited in the CIViC curation process, with examples to guide contributors.
* **Ensure transparency** to CIViC users and fellow contributors regarding when and how AI has assisted curation and editorial efforts, building trust through disclosure and review.

These policies apply to all community members, curators, editors, and administrators involved in CIViC curation, moderation, or content development. They cover textual content contributions (e.g. evidence summaries, gene/variant descriptions, etc.), and structured entity attributes (e.g. evidence/assertion type, direction, disease, codes, guidelines etc.), and review of submitted records.

Policy Overview
~~~~~~~~~~~~~~~

In brief, CIViC allows the use of AI tools for supportive tasks in the curation and editorial workflows, provided that those uses are accompanied by careful human verification and transparency. Conversely, any use of AI that could compromise human accountability, accuracy, verifiability, or the community’s trust is prohibited. All contributors must adhere to the specific allowances and prohibitions below.

Allowed Uses of AI in CIViC
~~~~~~~~~~~~~~~~~~~~~~~~~~~

CIViC acknowledges that when used responsibly, AI-based tools can save time, assist curators, and facilitate creativity and spontaneous discovery. The following uses of AI are permitted under the conditions stated:

* **Language and Grammar Assistance:** You may use AI tools to improve the clarity, grammar, or spelling of text that *you* have written for CIViC. For example, it is acceptable to have an AI suggest rewording of an evidence summary for readability or to fix typos. **Conditions:** The curator must review all AI-suggested edits to ensure they do not alter the scientific meaning or introduce errors. *Minor copy-editing by AI does not require formal disclosure*, but the curator remains accountable for the final wording.
* **Summarizing Published Literature:** AI may be used to generate a draft summary of a scientific article or evidence *after you have read the source*. For instance, in the process of writing an evidence statement, a curator might input a well-understood paper’s abstract or findings into an AI assistant to obtain a preliminary summary, which the curator may then refine. **Conditions:** The curator must have read the source material themselves and must verify every point in the AI-generated draft against the original paper to ensure that the summary is faithfully supported by the source. The AI is just a drafting aid. The human expert *must ensure the draft summary is accurate and complete*. Any AI-derived text should be substantially edited by the curator before submission for editorial approval.
* **Idea Generation and Research Aid:** It is acceptable to use AI tools as a research assistant. For example, to help brainstorm search terms, to find relevant papers, or to outline the structure of an evidence statement. AI might also be used to translate a non-English paper to help understand it before curation. **Conditions:** Such uses are meant to *assist* the curator’s own thinking. The curator should critically evaluate any AI suggestions (e.g. by double-checking that suggested papers are real, relevant, and valid). AI may inform your research, but *it must not replace standard literature review practices*. Always retrieve and read the actual papers; do not rely on an AI summary alone.
* **Formatting, Tagging, and Data Handling:** AI or automated scripts may be used to help with non-content tasks such as formatting bibliography references, converting data between formats, or suggesting controlled vocabulary terms to speed up curation (e.g. mapping a drug name to a standardized ontology term). **Conditions:** The output of such tools must be reviewed (e.g. to ensure the suggested ontology ID truly matches the intended drug). When using any automation for bulk edits or formatting, you must test it using a representative sample and verify correctness before applying widely.
* **Internal QA and Detection:** CIViC editors or admins may use AI-driven software to detect potential issues and perform quality assurance (e.g. verification of structured attributes, filtering AI-generated text). **Conditions:** Any such tools will be used as an initial filter; flagged content will be reviewed by human moderation. Decisions like rejecting revisions or approving content will not be made by AI alone. A human editor will always assess the situation and make the final call.

In all allowed cases above, *the primary requirement is that a human remains in full control*. AI must only assist their knowledge work, and every piece of content added to CIViC must be vetted and approved by a human expert. If you cannot confidently verify or understand the output of an AI, you *must not use it* while performing curation in CIViC.

Prohibited Uses of AI in CIViC
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Certain applications of AI are strictly disallowed in CIViC curation due to the high risk of introducing incorrect, unverified, or unethical content. Do not engage in these practices:

* **No Fully AI-Generated Submissions:** *Do not submit content that was entirely or primarily written by an AI without human contribution.* For example, you must not use an AI to generate an evidence summary and simply paste it into an evidence item submission or revision. Any text added to CIViC should be *substantially written or edited* by a human curator based on actual source material. Submitting raw AI output as if it were your own work, or if it were verified knowledge is forbidden.
* **No AI-Only Interpretations or Conclusions:** CIViC exists to catalog expert interpretations of cancer variants based on published evidence. *AI should not be used to formulate novel interpretations or clinical significance assessments that extend beyond the source data.* In other words, an AI must not be asked to “decide” the clinical relevance of a variant, or to predict treatment outcomes that haven’t been vetted by a human domain expert. All assertions in CIViC *must come from real, published scientific evidence*, not AI conjecture. Using an AI to fill in knowledge gaps or to extrapolate findings is considered original research and is not allowed.
* **No Undisclosed AI Co-production:** If a significant portion of the text or analysis you plan to contribute was assisted by AI, you *may not conceal that fact.* While we don’t require a formal citation of AI usage in the content, we do require transparency in practice. This means you should not pass off AI-written text as solely your own writing when it hasn’t been verified. Ghostwriting by AI is prohibited. Failing to disclose or acknowledge heavy AI assistance (for instance, if an editor asks about the origin of an evidence summary) would violate community trust. Always be ready to explain your sources or process, or simply avoid using AI in any way that you feel needs to be hidden.
* **No AI-Generated References or Data:** CIViC entries must be grounded in real, published scientific literature. Therefore, adding citations provided by an AI without independently verifying them is prohibited. AI tools are notorious for generating fake article references or mixing up data. Every reference and source in CIViC must be checked for existence, relevance, and validity. Similarly, do not add or suggest revisions with data from an AI’s output that you cannot trace back to an authoritative source. *Only use actual data from permitted sources* (e.g. PubMed papers, ASCO abstracts, ASH publications), or databases (e.g. Human Phenotype Ontology, Drug Gene Interaction Database).
* **No Automated Bulk Content Creation:** Any attempt to use AI to mass-produce content or make bulk edits in CIViC (for example, generating dozens of evidence statement revisions via scripted API submissions) is forbidden unless explicitly approved by the CIViC team in a controlled setting. Unsupervised bulk additions often yield errors that can overwhelm the review process. The quality of each contribution is far more important than quantity. We prefer one well-curated entry over many AI-generated entries of dubious accuracy or provenance. This prohibition includes the use of AI to automatically “scrape” external sources and populate CIViC without curator oversight. Integration of sources must proceed through CIViC’s human curation workflow.
* **No Confidential or Proprietary Data in AI Queries:** While CIViC itself is an open resource, contributors might at times have access to pre-publication data or non-public discussion (e.g. a draft publication under review). *Do not include any confidential or sensitive information in queries to AI tools*. For example, if you are privately sent information or data about a novel, unpublished variant, you may not use AI or a similar service to analyze that data. Even if the use of an AI provides a means to construct a parallel justification for a novel submission or revision to CIViC records, doing so could violate the privacy or terms under which the information was shared. In general, only use AI on information that is already public, from a source or database available in CIViC submission and revision forms.

Contributor Responsibilities and Verification
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

If you choose to use AI in any allowed manner while contributing to CIViC, you carry the following responsibilities:

* **Thorough Verification:** You must carefully review and verify all AI-assisted content before including it in any CIViC submission, revision, or comment. This means reading the original scientific sources to confirm every fact, cross-checking any claims, and ensuring that nothing was lost or added incorrectly by the AI. If an AI summary leaves out crucial details or citations, you are responsible for catching and fixing it. If you are not willing or able to do this level of verification, do not use AI tools. Instead, rely on your own summarization of the source.
* **Maintaining Scientific Accuracy and Tone:** Ensure that AI usage does not introduce ambiguity, irrelevant context, or overly general statements. CIViC entries must be precise, relevant, and valid. Often, AI-generated text can sound authoritative but may slightly distort the meaning or confidence level of a statement. It is your job to ensure the content remains scientifically accurate, properly qualified, and aligned with the source’s intent. Edit phrasing as needed to fit CIViC’s style (concise, evidence-focused), and remove any filler or unsupported statements the AI might have included.
* **Transparency with Fellow Contributors:** While we do not yet require declaration of AI use in submissions, revisions, or comments, within the CIViC community you should be open about your use of AI if it is relevant or if you are asked. For example, if an editor reviews your contribution and inquires about how a certain phrasing was derived, or the source of a variant coordinate, it is best to mention if an AI tool was used in its writing or discovery. This allows additional scrutiny, since AI can occasionally produce subtle inaccuracies. Honest communication will ensure that AI usage remains a helpful tool and not a hidden risk. Remember, there is no shame in using an AI to assist. The goal is to integrate AI usage into CIViC curation workflows transparently and carefully.
* **Continuous Learning and Adaptation:** AI tools and best practices are evolving, therefore contributors are expected to stay informed on CIViC’s updates to this policy, and emerging community standards. If new guidelines or features (e.g. an “AI assistance used” checkbox) are introduced, comply with them. Share your experiences: if you find a certain AI tool particularly useful or problematic for curation, notify the community so that we may learn together. Report any issues where AI produced incorrect content that was almost submitted, as these anecdotes can help refine our guidance.

Enforcement and Monitoring
~~~~~~~~~~~~~~~~~~~~~~~~~~

CIViC operates on community trust and the dedication of its expert curators and editors. We expect adherence to this policy as part of our overall code of conduct and content standards. Instances of clear abuse or negligence involving AI will be handled by administrators:

* **Violations:** Content found to violate the Prohibited Uses (for example, an entry with fabricated or unverified information clearly including AI generated content) will be rejected or reverted. The contributor will be informed of the reasons and pointed back to this policy for guidance, and given a chance to resubmit after proper human curation.
* **Burden of Proof**: If a CIViC curator suspects that a submission or revision was AI-generated without proper verification (e.g. it contains hallmarks of AI text or errors that suggest an unchecked AI output), they may flag it for review. The burden of proof is on the contributor to show that the content is based on real sources and meets CIViC standards. Editors may reach out to the contributor for clarification, asking for the sources used or whether AI played a role.
* **Sanctions:** Repeat or egregious violations (for instance, mass-submitting AI generated entries without approval or attempt at verification) will result in account sanctions. This may include temporary or permanent suspension of privileges or access, depending on severity. We take the quality of CIViC’s contents, and the human accountability of its editorial workflows very seriously, especially because real  research decisions could be influenced by our interpretations. Deliberately or recklessly injecting bad information via AI is grounds for strict action.
* **Monitoring:** The CIViC team may employ tools to help detect AI-generated text, structured attributes, or unusual editing patterns. While no detection method is foolproof, we will use them in combination with human oversight. However, we primarily rely on the community’s watchfulness and the editorial review process to catch problematic content. Every curatable entity (e.g. evidence items, assertions) undergoes expert moderation before approval. During this, any content that seems inconsistent with its source, or contains suspicious statements will get extra scrutiny. This policy empowers editors to question submissions and revisions if AI misuse is suspected.
* **Appeals and Discussions:** We encourage open dialogue. If a contribution of yours is flagged for AI-related reasons and you believe it was a misunderstanding, you can appeal by discussion in the associated comment threads. Perhaps you did verify a statement properly, but wrote in a style that resembles AI produced text. Clearing that up will help. Our aim is not to punish, but to ensure quality. We will gladly approve content that is proven to be human-curated and of good quality. These policies will be periodically revisited as AI and community needs evolve, and any feedback provided by community members will be incorporated into future policies.

Examples of Allowed vs. Disallowed AI Use
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To clarify the intent of the above rules, here are some concrete examples demonstrating what is and is not acceptable in terms of AI-assisted work in CIViC:

* **Allowed Example \- AI-Assisted Draft with Verification:** A curator is creating a new evidence item from a source suggestion, a research paper about a BRAF mutation’s response to a therapy. They first read the paper in full. To save time, they upload the paper to NotebookLM, and query it: *“Summarize the key findings of the source on BRAF V600E and vemurafenib efficacy.”* The AI returns a three paragraph summary. The curator uses this as a starting point, and proceeds to cross-check each fact: they compare the AI summary to the paper’s results section, correcting a couple of details the AI got wrong about patient numbers, adjusts the tone of a statement without support to justify its confidence, and trims any generic sentences. They then format the evidence statement to fit CIViC’s concise style. In their submission comment, they might note, “Initial summary drafted with the assistance of NotebookLM, then verified and edited by myself.” This is permitted because the curator used AI in a supporting role, fully vetted the content, and rewrote most of the statement in their own words. The AI sped up the work, but did not introduce unchecked information.
* **Allowed Example \- Grammar and Clarity Improvement:** A curator wishes to submit an evidence statement, however English is not their first language. They initially write their statement in a text editor, then paste it into ChatGPT, prompting it to propose clearer phrasing and correct any grammar issues. ChatGPT generates a statement that provides clearer phrasing for a couple of sentences and corrects grammar issues (e.g. changing passive voice to active, fixing tenses). The curator reviews these changes to their original work to ensure the meaning remains unchanged, and then includes this statement in their evidence item submission. They do not feel the need to announce these micro-edits. This is allowed. Here, the AI acts like an advanced grammar assistant. No new scientific content was added by the AI, which only improved readability. The curator remains responsible for the content, and has confirmed their evidence statement accurately reflects its source.
* **Disallowed Example \- Unverified AI Content:** A new contributor decides to add an evidence item, but hasn’t found a reference. They ask ChatGPT: *“What does TP53 R175H do in cancer?”*, which responds with a plausible-sounding explanation and citations. The citations prove to be hallucinated, but the contributor searches for a PubMed article that includes references to *TP53* and *R175H* to obtain a valid PubMed ID. They paste ChatGPT’s response into the evidence statement, provide the PubMed ID, and briefly scan the paper, making their best guess for the form’s required attributes to submit it for editorial review. This is not allowed. Because they didn’t critically engage with the content, their evidence statement likely contains errors, misinterpretations, or hallucinations. Their choices for structured attributes are unjustified and likely incorrect. By submitting this evidence item, they have introduced potentially false information into CIViC, undermining the database’s reliability. Such a submission would be rejected in editorial review, and the contributor counseled on the proper curation and submission process.

These examples are intended to illustrate the line between using AI as a helpful assistant versus over-relying on it to replace human thought and accountability in ways that break our policies. When in doubt, err on the side of caution: do more manual verification and involve others in reviewing the content.

Conclusion and Future Considerations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

CIViC’s AI Editorial Policy is meant to safeguard the quality of our collective work while permitting contributors to benefit from modern tools. We recognize that AI technology is rapidly evolving, and therefore will adapt our policies as needed. For instance, if new tools emerge that are specifically designed for biomedical curation with high reliability, we may pilot their use under guided conditions. Conversely, if we encounter new types of AI-related problems (e.g. subtle, difficult to detect biases introduced by AI in our curation workflows), we will update our policies to address them.

Ultimately, our community’s expertise and diligence comprise the core of CIViC. AI may augment your efforts, but must not replace the insight you bring as domain experts. By following these policies, we ensure that CIViC remains an authoritative and trusted knowledgebase, even as we incorporate new technologies.

**Policy Version:** 1.0 (December 2025\) \- Prepared by the CIViC leadership team with input from community members, drawing on the best practices from scientific journals and open knowledge projects.

**AI Usage Disclosure:** AI was used in the production of this document to summarize the current AI policies from top scientific journals and open-knowledge projects, then generate an initial draft from which these policies were derived after extensive corrections, extensions, contributions, and editing.